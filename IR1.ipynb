{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964342cb-388a-48c2-b967-5f25a27fea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/emmanuel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f9528ad-8514-4b6e-9338-e7d77f43860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, item):\n",
    "        self.item = item\n",
    "        self.next = None\n",
    "\n",
    "class LL:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    def add_node(self,val):\n",
    "        newNode = Node(val)\n",
    "        if not self.head:\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp:\n",
    "            if val == temp.item:\n",
    "                return\n",
    "            temp = temp.next\n",
    "        if self.head.item > val:\n",
    "            newNode.next = self.head\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp and temp.next:\n",
    "            if val < temp.next.item:\n",
    "                break\n",
    "            temp = temp.next\n",
    "        newNode.next = temp.next\n",
    "        temp.next = newNode\n",
    "                    \n",
    "    def print_list(self):\n",
    "        tmp = self.head\n",
    "        while tmp:\n",
    "            print(tmp.item, end=' ')\n",
    "            tmp = tmp.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b722bd-d5ed-4433-9189-c97582a337d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Stopword-List.txt', 'r')\n",
    "stop = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f85b1c-90ce-41e8-856c-5e17749a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\w+(?:['-,]\\w+)?|[^_\\w\\s()]\"\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33c8f116-e1cb-47b9-9487-2cfe98023488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "dic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for t in tokens:\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in dic:\n",
    "                        dic[term] = LL()\n",
    "                    dic[term].add_node(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b11e3b21-fe73-4163-9a8f-55df8abc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"inverted_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dic, f)\n",
    "\n",
    "with open(\"docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15aad3c2-502f-4e72-9aa4-4c88c50cfbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LL object at 0x7f56b333f9d0>\n"
     ]
    }
   ],
   "source": [
    "A = set()\n",
    "B = set()\n",
    "C = set()\n",
    "a = dic[ps.stem('cancer')].head\n",
    "b = dic[ps.stem('learning')].head\n",
    "# c = dic[ps.stem('classification')].head\n",
    "\n",
    "while a:\n",
    "    A.add(a.item)\n",
    "    a = a.next\n",
    "while b:\n",
    "    B.add(b.item)\n",
    "    b = b.next\n",
    "# while c:\n",
    "#     C.add(c.item)\n",
    "#     c = c.next\n",
    "\n",
    "# print(A.intersection(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e7b52c4-5130-4777-85ad-121506535730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "\n",
    "posDic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for index, t in enumerate(tokens):\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in posDic:\n",
    "                        posDic[term] = dict()\n",
    "                    if doc not in posDic[term]:\n",
    "                        posDic[term][doc] = LL()\n",
    "                    posDic[term][doc].add_node(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8939e4db-492d-4598-9ebc-cb9dfbfa99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positional_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(posDic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb63e608-3856-4980-a5d6-5e1c19fbb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 250 268 413 554 710 1040 1685 1888 2317 2547 2987 3197 3374 3387 3463 3472 3610 3673 3825 3842 4413 4899 5271 5505 5545 5560 5565 5603 5616 5669 5686 5703 5714 5742 5749 5758 5788 5795 5802 5838 5843 5861 5969 6035 6039 6226 6233 6244 6302 6772 6819 6955 7032 7087 7139 7169 7243 7249 7328 7340 7383 7430 7465 7477 7508 7545 7555 7606 7636 7688 7720 7736 7768 7814 7819 7869 7875 7910 7918 7954 7959 7997 8046 8081 8093 8128 8228 8310 8354 8388 8398 8432 8478 8490 8809 "
     ]
    }
   ],
   "source": [
    "posDic['heart'][8].print_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
