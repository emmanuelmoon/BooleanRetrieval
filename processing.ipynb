{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964342cb-388a-48c2-b967-5f25a27fea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/emmanuel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9528ad-8514-4b6e-9338-e7d77f43860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, item):\n",
    "        self.item = item\n",
    "        self.next = None\n",
    "\n",
    "class LL:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    def add_node(self,val):\n",
    "        newNode = Node(val)\n",
    "        if not self.head:\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp:\n",
    "            if val == temp.item:\n",
    "                return\n",
    "            temp = temp.next\n",
    "        if self.head.item > val:\n",
    "            newNode.next = self.head\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp and temp.next:\n",
    "            if val < temp.next.item:\n",
    "                break\n",
    "            temp = temp.next\n",
    "        newNode.next = temp.next\n",
    "        temp.next = newNode\n",
    "                    \n",
    "    def print_list(self):\n",
    "        tmp = self.head\n",
    "        while tmp:\n",
    "            print(tmp.item, end=' ')\n",
    "            tmp = tmp.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b722bd-d5ed-4433-9189-c97582a337d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Stopword-List.txt', 'r')\n",
    "stop = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f85b1c-90ce-41e8-856c-5e17749a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\b(?![0-9])\\w+(?:['-]\\w+)?|[^_\\w\\s()@#$%^&*+={[\\]};,<>./?~`]\"\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33c8f116-e1cb-47b9-9487-2cfe98023488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "dic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for t in tokens:\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in dic:\n",
    "                        dic[term] = LL()\n",
    "                    dic[term].add_node(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11e3b21-fe73-4163-9a8f-55df8abc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"inverted_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dic, f)\n",
    "\n",
    "with open(\"docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15aad3c2-502f-4e72-9aa4-4c88c50cfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = set()\n",
    "B = set()\n",
    "C = set()\n",
    "a = dic[ps.stem('cancer')].head\n",
    "b = dic[ps.stem('learning')].head\n",
    "# c = dic[ps.stem('classification')].head\n",
    "\n",
    "while a:\n",
    "    A.add(a.item)\n",
    "    a = a.next\n",
    "while b:\n",
    "    B.add(b.item)\n",
    "    b = b.next\n",
    "# while c:\n",
    "#     C.add(c.item)\n",
    "#     c = c.next\n",
    "\n",
    "# print(A.intersection(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7b52c4-5130-4777-85ad-121506535730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "\n",
    "posDic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for index, t in enumerate(tokens):\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in posDic:\n",
    "                        posDic[term] = dict()\n",
    "                    if doc not in posDic[term]:\n",
    "                        posDic[term][doc] = LL()\n",
    "                    posDic[term][doc].add_node(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8939e4db-492d-4598-9ebc-cb9dfbfa99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positional_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(posDic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb63e608-3856-4980-a5d6-5e1c19fbb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 208 222 335 415 519 789 1317 1475 1791 1991 2335 2447 2586 2650 2656 2776 2826 2938 2947 3406 3820 4080 4254 4278 4291 4295 4318 4330 4369 4386 4401 4409 4426 4433 4441 4459 4466 4472 4493 4497 4508 4588 4632 4635 4753 4760 4771 4807 5112 5144 5226 5277 5317 5345 5364 5409 5415 5464 5475 5504 5534 5556 5567 5587 5611 5621 5656 5679 5708 5729 5744 5764 5797 5801 5837 5842 5867 5872 5896 5900 5925 5959 5980 5991 6012 6079 6134 6163 6186 6195 6215 6244 6255 6446 "
     ]
    }
   ],
   "source": [
    "posDic['heart'][8].print_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
