{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "964342cb-388a-48c2-b967-5f25a27fea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/emmanuel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f9528ad-8514-4b6e-9338-e7d77f43860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, item):\n",
    "        self.item = item\n",
    "        self.next = None\n",
    "\n",
    "class LL:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    def add_node(self,val):\n",
    "        newNode = Node(val)\n",
    "        if not self.head:\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp:\n",
    "            if val == temp.item:\n",
    "                return\n",
    "            temp = temp.next\n",
    "        if self.head.item > val:\n",
    "            newNode.next = self.head\n",
    "            self.head = newNode\n",
    "            return\n",
    "        temp = self.head\n",
    "        while temp and temp.next:\n",
    "            if val < temp.next.item:\n",
    "                break\n",
    "            temp = temp.next\n",
    "        newNode.next = temp.next\n",
    "        temp.next = newNode\n",
    "                    \n",
    "    def print_list(self):\n",
    "        tmp = self.head\n",
    "        while tmp:\n",
    "            print(tmp.item, end=' ')\n",
    "            tmp = tmp.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9b722bd-d5ed-4433-9189-c97582a337d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Stopword-List.txt', 'r')\n",
    "stop = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07f85b1c-90ce-41e8-856c-5e17749a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\b(?![0-9])\\w+(?:\\w+)?|[^-_\\w\\s()@#$%^&*+={[\\]};,<>./?~`]\"\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33c8f116-e1cb-47b9-9487-2cfe98023488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "dic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for t in tokens:\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in dic:\n",
    "                        dic[term] = LL()\n",
    "                    dic[term].add_node(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b11e3b21-fe73-4163-9a8f-55df8abc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"inverted_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dic, f)\n",
    "\n",
    "with open(\"docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15aad3c2-502f-4e72-9aa4-4c88c50cfbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17170\n"
     ]
    }
   ],
   "source": [
    "# A = set()\n",
    "# B = set()\n",
    "# C = set()\n",
    "# a = dic[ps.stem('cancer')].head\n",
    "# b = dic[ps.stem('learning')].head\n",
    "# c = dic[ps.stem('classification')].head\n",
    "\n",
    "# while a:\n",
    "#     A.add(a.item)\n",
    "#     a = a.next\n",
    "# while b:\n",
    "#     B.add(b.item)\n",
    "#     b = b.next\n",
    "# while c:\n",
    "#     C.add(c.item)\n",
    "#     c = c.next\n",
    "\n",
    "# print(A.intersection(B))\n",
    "# dic[ps.stem(\"don't\")]\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e7b52c4-5130-4777-85ad-121506535730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "docs = set()\n",
    "\n",
    "posDic = {}\n",
    "punc = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '+', '=', '{', '[', ']', '}', ':', ';', \"'\", '\"', ',', '<', '>', '.', '/', '?', '~', '`']\n",
    "\n",
    "for subdir, dirs, files in os.walk('ResearchPapers'):\n",
    "    for file in files:\n",
    "        with open(subdir + os.sep + file, 'r', encoding='cp1252') as txt:\n",
    "            doc = re.search('[0-9]*', file).group()\n",
    "            doc = int(doc)\n",
    "            docs.add(doc)\n",
    "            tokens = tokenize(txt.read())\n",
    "            for index, t in enumerate(tokens):\n",
    "                if t not in stop and t not in punc:\n",
    "                    term = ps.stem(t.lower())\n",
    "                    if term not in posDic:\n",
    "                        posDic[term] = dict()\n",
    "                    if doc not in posDic[term]:\n",
    "                        posDic[term][doc] = LL()\n",
    "                    posDic[term][doc].add_node(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8939e4db-492d-4598-9ebc-cb9dfbfa99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positional_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(posDic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb63e608-3856-4980-a5d6-5e1c19fbb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 207 221 332 412 520 787 1308 1463 1789 1982 2324 2438 2569 2579 2641 2647 2762 2812 2930 2941 3396 3802 4042 4212 4236 4249 4253 4275 4287 4326 4343 4358 4366 4383 4390 4398 4415 4422 4428 4449 4453 4463 4544 4587 4590 4706 4713 4724 4759 5057 5089 5173 5223 5262 5290 5309 5354 5360 5409 5420 5448 5479 5500 5511 5530 5553 5563 5596 5619 5649 5670 5685 5704 5736 5740 5775 5780 5805 5811 5834 5838 5863 5895 5915 5926 5947 6016 6072 6100 6122 6131 6151 6180 6190 6380 "
     ]
    }
   ],
   "source": [
    "posDic['heart'][8].print_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
